{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('faceRec': conda)"
  },
  "interpreter": {
   "hash": "0ad30ecd5c8a07a9c672184f072e2306d784de53c545b88b9351dec71578278b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import dlib\n",
    "import cv2\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag = cv2.imread('./myImage2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',imag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(original_image,face_with_landmarks, desired_left_eye=(0.33,0.33), desired_nose=(0.5,0.5)):\n",
    "    \n",
    "    faceX, faceY, face_width, face_height = face_with_landmarks['box']\n",
    "    left_eye = np.array(face_with_landmarks['keypoints']['left_eye'])\n",
    "    right_eye = np.array(face_with_landmarks['keypoints']['right_eye'])\n",
    "    eye_center = (left_eye + right_eye)/2\n",
    "    \n",
    "    nose = np.array(face_with_landmarks['keypoints']['nose'])\n",
    "    nose_distance = np.sum((eye_center - nose)**2)\n",
    "    # print(\"nose_distance \",nose_distance)\n",
    "    eyes_distance = np.sum((left_eye - right_eye)**2)\n",
    "    # print(\"eyes_distance \",eyes_distance)\n",
    "    input_points = np.float32([left_eye, right_eye, nose])\n",
    "\n",
    "    scaling_factor = nose_distance/eyes_distance \n",
    "    # print(\"scaling factor \",scaling_factor)\n",
    "    desired_nose = np.array([0.5,2*desired_left_eye[1]-(1-2*desired_left_eye[0])*scaling_factor])\n",
    "    # print(\"desired nose \",desired_nose)\n",
    "\n",
    "    desired_right_eye = np.array([1-desired_left_eye[0],desired_left_eye[1]])*np.array([face_width,face_height])\n",
    "    desired_left_eye = np.array(desired_left_eye)*np.array([face_width,face_height])\n",
    "\n",
    "    desired_nose = desired_nose*np.array([face_width,face_height])\n",
    "\n",
    "    output_points = np.float32([desired_left_eye, desired_right_eye, desired_nose]) \n",
    "\n",
    "    M = cv2.getAffineTransform(input_points, output_points)\n",
    "    \n",
    "    dst = cv2.warpAffine(original_image, M,(face_width,face_height))\n",
    "    return dst \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D1621D3DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[{'box': [277, 457, 264, 336], 'confidence': 0.9893486499786377, 'keypoints': {'left_eye': (345, 567), 'right_eye': (468, 585), 'nose': (384, 638), 'mouth_left': (332, 703), 'mouth_right': (431, 722)}}]\n"
     ]
    }
   ],
   "source": [
    "faces = model.detect_faces(imag)\n",
    "print(faces)\n",
    "cv2.imshow(\"cropped image\",imag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nose_distance  4350.25\neyes_distance  15453\nscaling factor  0.28151491619750213\ndesired nose  [0.5        0.56428493]\n(336, 264, 3)\n"
     ]
    }
   ],
   "source": [
    "for face in faces:\n",
    "    newImage =normalise(imag,face)\n",
    "    print(newImage.shape)\n",
    "    cv2.imshow(\"cropped image\",newImage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_facenet import FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nose_distance  9518.5\n",
      "eyes_distance  32050\n",
      "scaling factor  0.29698907956318255\n",
      "desired nose  [0.5        0.55902371]\n",
      "nose_distance  564.5\n",
      "eyes_distance  2450\n",
      "scaling factor  0.2304081632653061\n",
      "desired nose  [0.5        0.58166122]\n",
      "(2, 512)\n"
     ]
    }
   ],
   "source": [
    "known_embeddings = []\n",
    "names = []\n",
    "\n",
    "embedder = FaceNet()\n",
    "imag = cv2.imread('./myImage.jpeg')\n",
    "faces = model.detect_faces(imag)\n",
    "for face in faces:\n",
    "    croppedFace = normalise(imag,face)\n",
    "    detections = embedder.extract(imag)\n",
    "    known_embeddings.append(detections[0]['embedding'])\n",
    "    names.append(\"pranay\")\n",
    "\n",
    "imag = cv2.imread('./joji.jpg')\n",
    "faces = model.detect_faces(imag)\n",
    "for face in faces:\n",
    "    croppedFace = normalise(imag,face)\n",
    "    detections = embedder.extract(imag)\n",
    "    known_embeddings.append(detections[0]['embedding'])\n",
    "    names.append(\"joji\")\n",
    "\n",
    "known_embeddings = np.array(known_embeddings)\n",
    "print(known_embeddings.shape)\n",
    "names = np.array(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nose_distance  1017.25\n",
      "eyes_distance  5185\n",
      "scaling factor  0.19619093539054966\n",
      "desired nose  [0.5        0.59329508]\n",
      "nose_distance  966.25\n",
      "eyes_distance  5501\n",
      "scaling factor  0.1756498818396655\n",
      "desired nose  [0.5        0.60027904]\n",
      "nose_distance  874.25\n",
      "eyes_distance  4105\n",
      "scaling factor  0.21297198538367845\n",
      "desired nose  [0.5        0.58758952]\n",
      "(512,)\n",
      "nose_distance  843.25\n",
      "eyes_distance  4225\n",
      "scaling factor  0.19958579881656804\n",
      "desired nose  [0.5        0.59214083]\n",
      "(512,)\n",
      "nose_distance  841.25\n",
      "eyes_distance  4229\n",
      "scaling factor  0.19892409553085835\n",
      "desired nose  [0.5        0.59236581]\n",
      "(512,)\n",
      "nose_distance  1093.0\n",
      "eyes_distance  4356\n",
      "scaling factor  0.25091827364554636\n",
      "desired nose  [0.5        0.57468779]\n",
      "(512,)\n",
      "nose_distance  870.5\n",
      "eyes_distance  4226\n",
      "scaling factor  0.2059867486985329\n",
      "desired nose  [0.5        0.58996451]\n",
      "(512,)\n",
      "nose_distance  996.25\n",
      "eyes_distance  4357\n",
      "scaling factor  0.2286550378700941\n",
      "desired nose  [0.5        0.58225729]\n",
      "(512,)\n",
      "nose_distance  934.25\n",
      "eyes_distance  4357\n",
      "scaling factor  0.2144250631168235\n",
      "desired nose  [0.5        0.58709548]\n",
      "(512,)\n",
      "nose_distance  65.0\n",
      "eyes_distance  100\n",
      "scaling factor  0.65\n",
      "desired nose  [0.5   0.439]\n",
      "nose_distance  853.25\n",
      "eyes_distance  4229\n",
      "scaling factor  0.20176164577914402\n",
      "desired nose  [0.5        0.59140104]\n",
      "(512,)\n",
      "nose_distance  871.25\n",
      "eyes_distance  4909\n",
      "scaling factor  0.1774801385210837\n",
      "desired nose  [0.5        0.59965675]\n",
      "(512,)\n",
      "nose_distance  1092.25\n",
      "eyes_distance  4649\n",
      "scaling factor  0.23494299849429984\n",
      "desired nose  [0.5        0.58011938]\n",
      "(512,)\n",
      "nose_distance  991.25\n",
      "eyes_distance  4477\n",
      "scaling factor  0.2214094259548805\n",
      "desired nose  [0.5       0.5847208]\n",
      "nose_distance  926.5\n",
      "eyes_distance  4346\n",
      "scaling factor  0.21318453750575242\n",
      "desired nose  [0.5        0.58751726]\n",
      "nose_distance  919.25\n",
      "eyes_distance  4477\n",
      "scaling factor  0.2053272280545008\n",
      "desired nose  [0.5        0.59018874]\n",
      "nose_distance  847.25\n",
      "eyes_distance  4229\n",
      "scaling factor  0.20034287065500117\n",
      "desired nose  [0.5        0.59188342]\n",
      "(512,)\n",
      "nose_distance  843.25\n",
      "eyes_distance  4229\n",
      "scaling factor  0.1993970205722393\n",
      "desired nose  [0.5        0.59220501]\n",
      "(512,)\n",
      "nose_distance  906.25\n",
      "eyes_distance  4229\n",
      "scaling factor  0.21429415937573895\n",
      "desired nose  [0.5        0.58713999]\n",
      "(512,)\n",
      "nose_distance  682.25\n",
      "eyes_distance  3973\n",
      "scaling factor  0.17172162094135415\n",
      "desired nose  [0.5        0.60161465]\n",
      "nose_distance  654.25\n",
      "eyes_distance  4105\n",
      "scaling factor  0.15937880633373935\n",
      "desired nose  [0.5        0.60581121]\n",
      "nose_distance  824.5\n",
      "eyes_distance  4490\n",
      "scaling factor  0.183630289532294\n",
      "desired nose  [0.5       0.5975657]\n",
      "(512,)\n",
      "nose_distance  73.0\n",
      "eyes_distance  100\n",
      "scaling factor  0.73\n",
      "desired nose  [0.5    0.4118]\n",
      "nose_distance  821.25\n",
      "eyes_distance  4365\n",
      "scaling factor  0.18814432989690721\n",
      "desired nose  [0.5        0.59603093]\n",
      "(512,)\n",
      "nose_distance  866.0\n",
      "eyes_distance  4628\n",
      "scaling factor  0.1871218668971478\n",
      "desired nose  [0.5        0.59637857]\n",
      "(512,)\n",
      "nose_distance  772.25\n",
      "eyes_distance  4357\n",
      "scaling factor  0.1772435161808584\n",
      "desired nose  [0.5       0.5997372]\n"
     ]
    }
   ],
   "source": [
    "vid=cv2.VideoCapture(0)\n",
    "processFrame = 0\n",
    "while(True):\n",
    "    ret,frame = vid.read()\n",
    "    # print(frame.shape)\n",
    "    if processFrame%2 == 0:\n",
    "        faces = model.detect_faces(frame)\n",
    "        for face in faces:\n",
    "            croppedFace = normalise(frame, face)\n",
    "            croppedFace = cv2.resize(croppedFace, (160,160))\n",
    "            embeddings_from_frame = embedder.extract(croppedFace)\n",
    "            # print(embeddings_from_frame)\n",
    "            if embeddings_from_frame != []:\n",
    "                embeddings_from_frame = np.array(embeddings_from_frame[0]['embedding'])\n",
    "                print(embeddings_from_frame.shape)\n",
    "                index = np.argmin(np.sum((known_embeddings-embeddings_from_frame)**2,axis=1))\n",
    "                x,y,w,h = face['box']\n",
    "                frame = cv2.rectangle(frame,(x,y),(x+width,y+height),(255,0,0),2)            \n",
    "                frame = cv2.putText(frame,names[index],(x+2,y+height),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2, cv2.LINE_AA)\n",
    "            cv2.imshow(\"frame\",frame)\n",
    "    processFrame = processFrame + 1\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "."
   ]
  }
 ]
}