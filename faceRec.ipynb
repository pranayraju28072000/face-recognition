{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('faceRec': conda)"
  },
  "interpreter": {
   "hash": "0ad30ecd5c8a07a9c672184f072e2306d784de53c545b88b9351dec71578278b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tf.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag = cv2.imread('./myImage2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',imag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(cropped_image,original_image,face_with_landmarks, desired_left_eye=(0.33,0.33), desired_nose=(0.5,0.5)):\n",
    "    \n",
    "    faceX, faceY, face_width, face_height = face_with_landmarks['box']\n",
    "    left_eye = np.array(face_with_landmarks['keypoints']['left_eye'])\n",
    "    right_eye = np.array(face_with_landmarks['keypoints']['right_eye'])\n",
    "    eye_center = (left_eye + right_eye)/2\n",
    "    \n",
    "    nose = np.array(face_with_landmarks['keypoints']['nose'])\n",
    "    nose_distance = np.sum((eye_center - nose)**2)\n",
    "    print(\"nose_distance \",nose_distance)\n",
    "    eyes_distance = np.sum((left_eye - right_eye)**2)\n",
    "    print(\"eyes_distance \",eyes_distance)\n",
    "    input_points = np.float32([left_eye, right_eye, nose])\n",
    "\n",
    "    scaling_factor = nose_distance/eyes_distance \n",
    "    print(\"scaling factor \",scaling_factor)\n",
    "    desired_nose = np.array([0.5,2*desired_left_eye[1]-(1-2*desired_left_eye[0])*scaling_factor])\n",
    "    print(\"desired nose \",desired_nose)\n",
    "\n",
    "    desired_right_eye = np.array([1-desired_left_eye[0],desired_left_eye[1]])*np.array([face_width,face_height])\n",
    "    desired_left_eye = np.array(desired_left_eye)*np.array([face_width,face_height])\n",
    "\n",
    "    # desired_nose = np.array(desired_nose)*np.array([face_width,face_height])\n",
    "    desired_nose = desired_nose*np.array([face_width,face_height])\n",
    "\n",
    "    output_points = np.float32([desired_left_eye, desired_right_eye, desired_nose]) \n",
    "\n",
    "    M = cv2.getAffineTransform(input_points, output_points)\n",
    "    \n",
    "    dst = cv2.warpAffine(original_image, M,(face_width,face_height))\n",
    "    return dst \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'box': [277, 457, 264, 336], 'confidence': 0.9893486499786377, 'keypoints': {'left_eye': (345, 567), 'right_eye': (468, 585), 'nose': (384, 638), 'mouth_left': (332, 703), 'mouth_right': (431, 722)}}]\n"
     ]
    }
   ],
   "source": [
    "faces = model.detect_faces(imag)\n",
    "print(faces)\n",
    "cv2.imshow(\"cropped image\",imag)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "faces detected\n",
      "[277, 457, 264, 336]\n",
      "(345, 567)\n",
      "(468, 585)\n",
      "nose_distance  4350.25\n",
      "eyes_distance  15453\n",
      "scaling factor  0.28151491619750213\n",
      "desired nose  [0.5        0.56428493]\n",
      "(336, 264, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for face in faces:\n",
    "    print(\"faces detected\")\n",
    "    x,y,width,height =face['box']\n",
    "    print(face[\"box\"])\n",
    "    landmarks = face['keypoints']\n",
    "    leye = landmarks['left_eye']\n",
    "    reye = landmarks['right_eye']\n",
    "    print(leye)\n",
    "    print(reye)\n",
    " \n",
    "    cv2.imshow(\"cropped image\",imag)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    newImage = imag[y:(y+height),x:(x+width)]\n",
    "    cv2.imshow(\"cropped image\",newImage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # newImage= facealigner(newImage,(x,y), leye, reye, height, width, (400,400),(0.2,0.2))\n",
    "    newImage =normalise(newImage,imag,face)\n",
    "    print(newImage.shape)\n",
    "    cv2.imshow(\"cropped image\",newImage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,width,height =faces[0]['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = cv2.rectangle(imag,(x,y),(x+width,y+height),(0,0,255))\n",
    "landmarks=faces[0]['keypoints']\n",
    "for i in landmarks:\n",
    "    rect=cv2.circle(rect,landmarks[i],3,(0,0,255))\n",
    "cv2.imshow(\"image\",rect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(391, 559)\n(570, 562)\n(477, 658)\n(398, 745)\n(548, 750)\n"
     ]
    }
   ],
   "source": [
    "landmarks=faces[0]['keypoints']\n",
    "for i in landmarks:\n",
    "    print(landmarks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid=cv2.VideoCapture(0)\n",
    "# processFrame = 0\n",
    "# while(True):\n",
    "#     ret,frame = vid.read()\n",
    "#     # print(frame.shape)\n",
    "#     if processFrame%2 == 0:\n",
    "#         faces = model.detect_faces(frame)\n",
    "#         for face in faces:\n",
    "#             box = face['box']\n",
    "#             frame = cv2.rectangle(frame,(box[0],box[1]),(box[0]+box[2],box[1]+box[3]),(0,0,255))\n",
    "#             landmarks = face['keypoints']\n",
    "#             for i in landmarks:\n",
    "#                 frame=cv2.circle(frame,landmarks[i],3,(0,0,255))\n",
    "#         cv2.imshow('detection',frame)\n",
    "#     processFrame = processFrame + 1\n",
    "#     if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "#         break\n",
    "\n",
    "# vid.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid=cv2.VideoCapture(0)\n",
    "processFrame = 0\n",
    "while(True):\n",
    "    ret,frame = vid.read()\n",
    "    # print(frame.shape)\n",
    "    if processFrame%2 == 0:\n",
    "        faces = model.detect_faces(frame)\n",
    "        for face in faces:\n",
    "            croppedFace = faces[]\n",
    "    processFrame = processFrame + 1\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}